{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "Load packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling POMCPOW [4c53ee00-974c-466f-8fa5-8dd73959bbab]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "On worker 2:\nArgumentError: Package OPS not found in current path:\n- Run `import Pkg; Pkg.add(\"OPS\")` to install the OPS package.\n\nrequire at ./loading.jl:893\ntop-level scope at none:1\neval at ./boot.jl:331\n#103 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/process_messages.jl:290\nrun_work_thunk at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/process_messages.jl:79\nrun_work_thunk at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/process_messages.jl:88\n#96 at ./task.jl:356\n\n...and 8 more exception(s).\n",
     "output_type": "error",
     "traceback": [
      "On worker 2:\nArgumentError: Package OPS not found in current path:\n- Run `import Pkg; Pkg.add(\"OPS\")` to install the OPS package.\n\nrequire at ./loading.jl:893\ntop-level scope at none:1\neval at ./boot.jl:331\n#103 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/process_messages.jl:290\nrun_work_thunk at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/process_messages.jl:79\nrun_work_thunk at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/process_messages.jl:88\n#96 at ./task.jl:356\n\n...and 8 more exception(s).\n",
      "",
      "Stacktrace:",
      " [1] sync_end(::Channel{Any}) at ./task.jl:314",
      " [2] macro expansion at ./task.jl:333 [inlined]",
      " [3] remotecall_eval(::Module, ::Array{Int64,1}, ::Expr) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/macros.jl:218",
      " [4] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/macros.jl:202",
      " [5] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091",
      " [6] execute_code(::String, ::String) at /home/wcy/.julia/packages/IJulia/a1SNk/src/execute_request.jl:27",
      " [7] execute_request(::ZMQ.Socket, ::IJulia.Msg) at /home/wcy/.julia/packages/IJulia/a1SNk/src/execute_request.jl:86",
      " [8] #invokelatest#1 at ./essentials.jl:710 [inlined]",
      " [9] invokelatest at ./essentials.jl:709 [inlined]",
      " [10] eventloop(::ZMQ.Socket) at /home/wcy/.julia/packages/IJulia/a1SNk/src/eventloop.jl:8",
      " [11] (::IJulia.var\"#15#18\")() at ./task.jl:356"
     ]
    }
   ],
   "source": [
    "# Initialize workers\n",
    "num_of_procs = 8 # You can also use addprocs() with no argument to create as many workers as your threads\n",
    "using Distributed\n",
    "addprocs(num_of_procs, exeflags=\"--project\") # initial workers with the project env in current work directory\n",
    "\n",
    "using ParallelExp\n",
    "\n",
    "@everywhere[\n",
    "    using POMDPs\n",
    "    using POMDPSimulators\n",
    "    using ParticleFilters\n",
    "    using POMDPPolicies\n",
    "    using BeliefUpdaters \n",
    "    \n",
    "    using POMCPOW\n",
    "    using BasicPOMCP\n",
    "    using PL_DESPOT\n",
    "    using OPS\n",
    "    using QMDP\n",
    "    ]\n",
    "\n",
    "# POMDP related pkgs\n",
    "# For roomba and BabyPOMDP belief updater\n",
    "\n",
    "# For visualization\n",
    "using D3Trees\n",
    "using POMDPModelTools\n",
    "using POMDPGifs\n",
    "import Cairo,Fontconfig\n",
    "\n",
    "# For data processing and storing\n",
    "using Statistics\n",
    "using DataFrames\n",
    "using CSV\n",
    "using Random\n",
    "using Printf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VDPTag2 Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCT-DESPOT\n",
    "@everywhere push!(LOAD_PATH, \"../../VDPTag2.jl\")\n",
    "@everywhere using VDPTag2\n",
    "using Plots\n",
    "using Reel\n",
    "using ProgressMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VDPTag2 Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pomdp = VDPTagPOMDP()\n",
    "\n",
    "# For POMCPOW\n",
    "random_value_estimator = FORollout(RandomPolicy(pomdp))\n",
    "value_estimator = FORollout(ToNextML(pomdp))\n",
    "pomcpow_dict = Dict(:default_action=>[RandomPolicy(pomdp),],\n",
    "                    :estimate_value=>[random_value_estimator],\n",
    "                    :tree_queries=>[200000,], \n",
    "                    :max_time=>[1.0,], \n",
    "                    :criterion=>[MaxUCB(30.),])\n",
    "\n",
    "# Solver list\n",
    "solver_list = [POMCPOWSolver=>pomcpow_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VDPTag2 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = POMCPOWSolver(tree_queries=200000, max_time=1.0, criterion=MaxUCB(30), estimate_value=random_value_estimator)\n",
    "\n",
    "# planner = solve(solver, pomdp)\n",
    "# hr = HistoryRecorder(max_steps=30)\n",
    "# belief_updater = SIRParticleFilter(pomdp, 2000)\n",
    "# hist = POMDPs.simulate(hr, pomdp, planner, belief_updater)\n",
    "\n",
    "# frames = Frames(MIME(\"image/png\"), fps=2)\n",
    "# gr()\n",
    "# @showprogress \"Creating gif...\" for i in 1:n_steps(hist)\n",
    "#     push!(frames, plot(pomdp, view(hist, 1:i)))\n",
    "# end\n",
    "\n",
    "# filename = string(\"VDPTag2.gif\")\n",
    "# write(filename, frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = POMCPOWSolver(tree_queries=200000,\n",
    "                        max_time=1.0,\n",
    "                        criterion=MaxUCB(30),\n",
    "                        k_action=1,\n",
    "                        alpha_action=0.2,\n",
    "                        k_observation=1,\n",
    "                        alpha_observation=0.2,\n",
    "                        estimate_value=value_estimator,\n",
    "                        tree_in_info=true)\n",
    "\n",
    "planner = solve(solver, pomdp)\n",
    "b0 = initialstate_distribution(pomdp)\n",
    "a, info = action_info(planner, b0)\n",
    "D3Tree(info[:tree], init_expand=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests based on VDPTag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_episodes = 100\n",
    "max_steps = 100\n",
    "rng = MersenneTwister(1)\n",
    "\n",
    "dfs = parallel_experiment(pomdp,\n",
    "                          number_of_episodes,\n",
    "                          max_steps,\n",
    "                          solver_list,\n",
    "                          initialstate=initialstate(pomdp, rng),\n",
    "                          full_factorial_design=false)\n",
    "\n",
    "CSV.write(\"VDPTag2_POMCPOW.csv\", dfs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete VDPTag2 Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pomdp = AODiscreteVDPTagPOMDP()\n",
    "\n",
    "# To-do\n",
    "# Transplant ManageUncertainty policy\n",
    "\n",
    "# For LB-DESPOT\n",
    "random_bounds = IndependentBounds(DefaultPolicyLB(RandomPolicy(pomdp)), 100.0, check_terminal=true)\n",
    "lbdespot_dict = Dict(:default_action=>[RandomPolicy(pomdp),], \n",
    "                    :bounds=>[random_bounds],\n",
    "                    :K=>[500, 300],\n",
    "                    :beta=>[0.5, 0., 0.1, 1., 5.])\n",
    "\n",
    "# For UCT-DESPOT\n",
    "random_rollout_policy = RandomPolicy(pomdp)\n",
    "uctdespot_dict = Dict(:default_action=>[RandomPolicy(pomdp),],\n",
    "                    :rollout_policy=>[random_rollout_policy],\n",
    "                    :max_trials=>[100000,],\n",
    "                    :K=>[500, 1000],\n",
    "                    :m=>[10, 30],\n",
    "                    :c=>[10.,])\n",
    "\n",
    "# Solver list\n",
    "solver_list = [LB_DESPOTSolver=>lbdespot_dict, \n",
    "                UCT_DESPOTSolver=>uctdespot_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete VDPTag2 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = LB_DESPOTSolver(bounds=random_bounds, beta=0.5, K=100, default_action=RandomPolicy(pomdp))\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=random_rollout_policy, max_trials=100000, m=10, K=500, c=10)\n",
    "\n",
    "# planner = solve(solver, pomdp)\n",
    "# hr = HistoryRecorder(max_steps=30)\n",
    "# belief_updater = SIRParticleFilter(pomdp, 2000)\n",
    "# hist = POMDPs.simulate(hr, pomdp, planner, belief_updater)\n",
    "\n",
    "# frames = Frames(MIME(\"image/png\"), fps=2)\n",
    "# gr()\n",
    "# @showprogress \"Creating gif...\" for i in 1:n_steps(hist)\n",
    "#     push!(frames, plot(pomdp, view(hist, 1:i)))\n",
    "# end\n",
    "\n",
    "# filename = string(\"Discrete_VDPTag2.gif\")\n",
    "# write(filename, frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = LB_DESPOTSolver(bounds=random_bounds, beta=0.0, K=100, default_action=RandomPolicy(pomdp), tree_in_info=true)\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=random_rollout_policy, max_trials=100000, m=10, K=500, c=10, tree_in_info=true)\n",
    "\n",
    "# planner = solve(solver, pomdp)\n",
    "# b0 = initialstate(pomdp)\n",
    "# a, info = action_info(planner, b0)\n",
    "# println(\"number of trials: $(info[:record][1])\")\n",
    "# println(\"time for building DESPOT: $(info[:record][2])\")\n",
    "# D3Tree(info[:tree], init_expand=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests based on Discrete VDPTag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_episodes = 100\n",
    "max_steps = 100\n",
    "rng = MersenneTwister(1)\n",
    "\n",
    "dfs = parallel_experiment(pomdp,\n",
    "                          number_of_episodes,\n",
    "                          max_steps,\n",
    "                          solver_list,\n",
    "                          initialstate=initialstate(pomdp, rng),\n",
    "                          full_factorial_design=false)\n",
    "\n",
    "CSV.write(\"DiscreteVDPTag2_LB-DESPOT.csv\", dfs[1])\n",
    "CSV.write(\"DiscreteVDPTag2_UCT-DESPOT.csv\", dfs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RockSample Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @everywhere push!(LOAD_PATH, \"../../RockSample.jl\")\n",
    "@everywhere using RockSample\n",
    "pomdp = RockSamplePOMDP(map_size=(7,8),\n",
    "                        rocks_positions=[(2,3), (1,8), (4,5), (5,2), (7,7)], \n",
    "                        sensor_efficiency=20.0,\n",
    "                        discount_factor=0.95, \n",
    "                        good_rock_reward = 20.0)\n",
    "\n",
    "# pomdp = RockSamplePOMDP(map_size=(11,11),\n",
    "#                         rocks_positions=[(2,8), (1,6), (4,9), (5,2), (8,7), (9,10), (11,2)], \n",
    "#                         sensor_efficiency=20.0,\n",
    "#                         discount_factor=0.95, \n",
    "#                         good_rock_reward = 20.0)\n",
    "\n",
    "# pomdp = RockSamplePOMDP(map_size=(15,15),\n",
    "#                         rocks_positions=[(2,3), (1,12), (4,1), (5,5), (8,15), (9,14), (12,1), (14,15), (15,7)], \n",
    "#                         sensor_efficiency=20.0,\n",
    "#                         discount_factor=0.95, \n",
    "#                         good_rock_reward = 20.0)\n",
    "\n",
    "\n",
    "# QMDP upper bound\n",
    "qmdp_policy = solve(QMDPSolver(), pomdp)\n",
    "function qmdp_upper_bound(pomdp, b)\n",
    "    return value(qmdp_policy, b)\n",
    "end\n",
    "\n",
    "# default policy\n",
    "move_east = FunctionPolicy() do b\n",
    "    return 2\n",
    "end\n",
    "\n",
    "to_best = FunctionPolicy() do b \n",
    "    if typeof(b) <: RSState \n",
    "        s = b \n",
    "        val, ind = findmax(s.rocks) \n",
    "    else \n",
    "        s = rand(b) \n",
    "        good_count = zeros(Int, length(s.rocks)) \n",
    "        for state in particles(b) \n",
    "            good_count += state.rocks \n",
    "        end \n",
    "        val, ind = findmax(good_count) \n",
    "    end \n",
    "    if val/length(s.rocks) < 0.5 \n",
    "        return 2 \n",
    "    end \n",
    "    rock_pos = pomdp.rocks_positions[ind]\n",
    "    diff = rock_pos - s.pos \n",
    "    if diff[2] != 0 \n",
    "        if sign(diff[2]) == 1 \n",
    "            return 1 # to north \n",
    "        else \n",
    "            return 3 # to south \n",
    "        end \n",
    "    else \n",
    "        if sign(diff[1]) == 1 \n",
    "            return 2 # to east \n",
    "        elseif sign(diff[1]) == -1 \n",
    "            return 4 # to west \n",
    "        else \n",
    "            return 5 # sample \n",
    "        end \n",
    "    end \n",
    "end\n",
    "\n",
    "# For LB-DESPOT\n",
    "random_bounds = IndependentBounds(DefaultPolicyLB(RandomPolicy(pomdp)), 30.0, check_terminal=true)\n",
    "bounds = IndependentBounds(DefaultPolicyLB(to_best), 30.0, check_terminal=true)\n",
    "bounds_hub = IndependentBounds(DefaultPolicyLB(to_best), qmdp_upper_bound, check_terminal=true)\n",
    "lbdespot_dict = Dict(:default_action=>[RandomPolicy(pomdp),], \n",
    "                    :bounds=>[random_bounds],\n",
    "                    :K=>[300, 100],\n",
    "                    :beta=>[0.5, 0., 0.1, 1., 5.])\n",
    "\n",
    "# For UCT-DESPOT\n",
    "random_rollout_policy = RandomPolicy(pomdp)\n",
    "uctdespot_dict1 = Dict(:default_action=>[RandomPolicy(pomdp),],\n",
    "                    :rollout_policy=>[random_rollout_policy],\n",
    "                    :max_trials=>[100000,],\n",
    "                    :K=>[1000, 2000],\n",
    "                    :m=>[50, 100],\n",
    "                    :c=>[1, 10.])\n",
    "uctdespot_dict2 = Dict(:default_action=>[RandomPolicy(pomdp),],\n",
    "                    :rollout_policy=>[random_rollout_policy],\n",
    "                    :max_trials=>[100000,],\n",
    "                    :K=>[300, 100, 500],\n",
    "                    :m=>[50, 30],\n",
    "                    :c=>[1.,10,])\n",
    "# For POMCPOW\n",
    "random_value_estimator = FORollout(RandomPolicy(pomdp))\n",
    "value_estimator = FORollout(to_best)\n",
    "pomcpow_dict = Dict(:default_action=>[RandomPolicy(pomdp),],\n",
    "                    :estimate_value=>[random_value_estimator],\n",
    "                    :tree_queries=>[200000,], \n",
    "                    :max_time=>[1.0,], \n",
    "                    :criterion=>[MaxUCB(10.),])\n",
    "\n",
    "# Solver list\n",
    "solver_list = [#LB_DESPOTSolver=>lbdespot_dict, \n",
    "                UCT_DESPOTSolver=>uctdespot_dict1,\n",
    "                UCT_DESPOTSolver=>uctdespot_dict2,] \n",
    "                #POMCPOWSolver=>pomcpow_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RockSample Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = LB_DESPOTSolver(bounds=random_bounds, beta=0.5, K=100, default_action=RandomPolicy(pomdp))\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=random_rollout_policy, max_trials=100000, m=10, K=500, c=10)\n",
    "# solver = POMCPOWSolver(tree_queries=200000, max_time=1.0, criterion=MaxUCB(30), estimate_value=random_value_estimator)\n",
    "\n",
    "# planner = solve(solver, pomdp)\n",
    "# makegif(pomdp, planner, filename=\"rock_sample.gif\", max_steps=100, show_progress=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = LB_DESPOTSolver(bounds=bounds_hub, beta=0.5, K=100, tree_in_info=true)\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=random_rollout_policy, max_trials=100000, m=50, K=1000, c=1, tree_in_info=true)\n",
    "# solver = POMCPOWSolver(tree_queries=200000, max_time=1.0, criterion=MaxUCB(10), estimate_value=value_estimator, tree_in_info=true)\n",
    "\n",
    "planner = solve(solver, pomdp)\n",
    "b0 = initialstate(pomdp)\n",
    "a, info = action_info(planner, b0)\n",
    "# println(\"number of trials: $(info[:record][1])\")\n",
    "# println(\"time for building DESPOT: $(info[:record][2])\")\n",
    "D3Tree(info[:tree], init_expand=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests based on RockSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_episodes = 100\n",
    "max_steps = 100\n",
    "rng = MersenneTwister(1)\n",
    "uctdespot_dict = Dict(:default_action=>[RandomPolicy(pomdp),],\n",
    "                    :rollout_policy=>[random_rollout_policy],\n",
    "                    :max_trials=>[100000,],\n",
    "                    :K=>[300,],\n",
    "                    :m=>[20,],\n",
    "                    :c=>[10.,])\n",
    "solver_list = [UCT_DESPOTSolver=>uctdespot_dict,] \n",
    "dfs = parallel_experiment(pomdp,\n",
    "                          number_of_episodes,\n",
    "                          max_steps,\n",
    "                          solver_list,\n",
    "                          initialstate=initialstate(pomdp, rng),\n",
    "                          full_factorial_design=true)\n",
    "\n",
    "# CSV.write(\"RockSample_LB-DESPOT.csv\", dfs[1])\n",
    "CSV.write(\"RockSample_UCT-DESPOT.csv\", dfs[1])\n",
    "# CSV.write(\"RockSample_POMCPOW.csv\", dfs[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BabyPOMDP Setting\n",
    "Setting up a BabyPOMDP problem for further using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using POMDPModels # For BabyPOMDP\n",
    "pomdp = BabyPOMDP(-5, -10, 0.1, 0.8, 0.1, 0.95) # defualt setting except that the discount is 0.95\n",
    "\n",
    "# Feed When Crying Policy\n",
    "@everywhere function feed_when_crying(b)\n",
    "    if typeof(b) == Bool\n",
    "        b \n",
    "    elseif (typeof(b) <: UCTDESPOT.ScenarioBelief || typeof(b) <: LBDESPOT.ScenarioBelief)\n",
    "        if typeof(currentobs(b)) <: Bool\n",
    "            currentobs(b)\n",
    "        else\n",
    "            pdf(currentobs(b), true) > 0.5\n",
    "        end\n",
    "    elseif typeof(b) <: POMDPModels.BoolDistribution\n",
    "        rand(b)\n",
    "    else\n",
    "        pdf(b, true) > 0.5\n",
    "    end\n",
    "end\n",
    "feed_when_crying_policy = solve(FunctionSolver(feed_when_crying), pomdp)\n",
    "\n",
    "# For LB-DESPOT\n",
    "# Assume all following rewards are coming from the worst case, \"hungry but don't feed\"\n",
    "@everywhere fval(m::BabyPOMDP, x) = reward(m, true, false)/(1-discount(m))\n",
    "bounds = IndependentBounds(DefaultPolicyLB(feed_when_crying_policy, final_value=fval), 0.0)\n",
    "random_bounds = IndependentBounds(DefaultPolicyLB(RandomPolicy(pomdp), final_value=fval), 0.0)\n",
    "lbdespot_dict = Dict(:default_action=>[feed_when_crying_policy,], \n",
    "                    :bounds=>[bounds, random_bounds],\n",
    "                    :K=>[1000, 2000, 3600, 5000],\n",
    "                    :beta=>[0., 0.1, 0.5, 1., 5.])\n",
    "\n",
    "# For UCT-DESPOT\n",
    "rollout_policy = feed_when_crying_policy\n",
    "random_rollout_policy = RandomPolicy(pomdp)\n",
    "uctdespot_dict = Dict(:rollout_policy=>[rollout_policy, random_rollout_policy],\n",
    "                        :K=>[1000, 2000, 3600, 5000],\n",
    "                        :m=>[30, 60, 100],\n",
    "                        :c=>[500., 1000., 2000.])\n",
    "\n",
    "# For POMCPOW\n",
    "value_estimator = PORollout(feed_when_crying_policy, PreviousObservationUpdater())\n",
    "random_value_estimator = FORollout(RandomPolicy(pomdp))\n",
    "pomcpow_dict = Dict(:estimate_value=>[value_estimator, random_value_estimator],\n",
    "                    :tree_queries=>[200000,], \n",
    "                    :max_time=>[1.0,], \n",
    "                    :criterion=>[MaxUCB(0.1), MaxUCB(1.0), MaxUCB(10.), MaxUCB(100.), MaxUCB(1000.)])\n",
    "\n",
    "# Solver list\n",
    "solver_list = [LB_DESPOTSolver=>lbdespot_dict, \n",
    "                UCT_DESPOTSolver=>uctdespot_dict, \n",
    "                POMCPOWSolver=>pomcpow_dict,\n",
    "                QMDPSolver=>Dict(:max_iterations=>[200,]),\n",
    "                FuncSolver=>Dict(:func=>[feed_when_crying,])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BabyPOMDP Visualization\n",
    "Visualize BabyPOMDP in form of a tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solver = LB_DESPOTSolver(bounds=bounds, beta=0.0, K=3000, default_action=feed_when_crying_policy, tree_in_info=true)\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=rollout_policy, m=1, K=1000, c=1000, tree_in_info=true)\n",
    "# solver = POMCPOWSolver(tree_queries=200000, max_time=1.0, criterion=MaxUCB(1), estimate_value=value_estimator, tree_in_info=true)\n",
    "\n",
    "planner = solve(solver, pomdp)\n",
    "b0 = initialstate_distribution(pomdp)\n",
    "a, info = action_info(planner, b0)\n",
    "# println(\"number of trials: $(info[:record][1])\")\n",
    "# println(\"time for building DESPOT: $(info[:record][2])\")\n",
    "# println(\"tree depth: $(info[:record][3])\")\n",
    "D3Tree(info[:tree], init_expand=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests based on BabyPOMDP\n",
    "First, run a simulation of one episode and one max step in case there's some latent bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_episodes = 1\n",
    "max_steps = 1\n",
    "rng = MersenneTwister(1)\n",
    "\n",
    "dfs = parallel_experiment(pomdp,\n",
    "                          number_of_episodes,\n",
    "                          max_steps,\n",
    "                          solver_list,\n",
    "                          initialstate=initialstate(pomdp, rng),\n",
    "                          full_factorial_design=false)\n",
    "\n",
    "# CSV.write(\"LaserTag_LB-DESPOT.csv\", dfs[1])\n",
    "CSV.write(\"LaserTag_UCT-DESPOT.csv\", dfs[2])\n",
    "# CSV.write(\"LaserTag_POMCPOW.csv\", dfs[3])\n",
    "# CSV.write(\"LaserTag_QMDP.csv\", dfs[4])\n",
    "# CSV.write(\"LaserTag_Move_Towards.csv\", dfs[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaserTag Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using LaserTag\n",
    "pomdp = gen_lasertag()\n",
    "belief_updater = SIRParticleFilter(pomdp, 10000)\n",
    "\n",
    "# Policies\n",
    "@everywhere function move_towards(b)\n",
    "    s = typeof(b) <: LTState ? b : rand(b)\n",
    "    \n",
    "    # try to sneak up diagonally\n",
    "    diff = s.opponent-s.robot\n",
    "    dx = diff[1]\n",
    "    dy = diff[2]\n",
    "    if abs(dx) == 1 && abs(dy) == 1\n",
    "        LaserTag.DIR_TO_ACTION[[dx, dy]]\n",
    "    elseif abs(dx) == 1\n",
    "        LaserTag.DIR_TO_ACTION[[0, sign(dy)]]\n",
    "    elseif abs(dy) == 1\n",
    "        LaserTag.DIR_TO_ACTION[[sign(dx), 0]]\n",
    "    else\n",
    "        LaserTag.DIR_TO_ACTION[[sign(dx), sign(dy)]]\n",
    "    end\n",
    "end\n",
    "move_towards_policy = solve(FunctionSolver(move_towards), pomdp)\n",
    "\n",
    "# QMDP upper bound\n",
    "qmdp_policy = solve(QMDPSolver(), pomdp)\n",
    "function qmdp_upper_bound(pomdp, b)\n",
    "    return value(qmdp_policy, b)\n",
    "end\n",
    "\n",
    "\n",
    "# For OPS\n",
    "bounds = OPS.IndependentBounds(RolloutLB(FORollout(move_towards_policy)), 10.0, check_terminal=true)\n",
    "bounds_hub = OPS.IndependentBounds(RolloutLB(FORollout(move_towards_policy)), qmdp_upper_bound, check_terminal=true)\n",
    "random_bounds = OPS.IndependentBounds(DefaultPolicyLB(RandomPolicy(pomdp)), 10.0, check_terminal=true)\n",
    "ops_dict = Dict(:default_action=>[move_towards_policy,],\n",
    "                    :bounds=>[bounds, random_bounds],\n",
    "                    :m=>[100, 300],\n",
    "                    )\n",
    "\n",
    "\n",
    "# For POMCPOW\n",
    "value_estimator = FORollout(move_towards_policy)\n",
    "random_value_estimator = FORollout(RandomPolicy(pomdp))\n",
    "pomcpow_dict = Dict(:estimate_value=>[value_estimator, random_value_estimator],\n",
    "                    :tree_queries=>[150000,], \n",
    "                    :max_time=>[1.0,], \n",
    "                    :criterion=>[MaxUCB(100),],\n",
    "                    :enable_action_pw=>[false,],\n",
    "                    :k_observation=>[2.,],\n",
    "                    :alpha_observation=>[0.15,])\n",
    "\n",
    "# Solver list\n",
    "solver_list = [OPSSolver=>ops_dict, \n",
    "                POMCPOWSolver=>pomcpow_dict,\n",
    "                QMDPSolver=>Dict(:max_iterations=>[200,]),\n",
    "                FuncSolver=>Dict(:func=>[move_towards,])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaserTag Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = OPSSolver(bounds=bounds, delta=0.5, K=500, tree_in_info=true)\n",
    "# solver = POMCPOWSolver(tree_queries=1000000,\n",
    "#                         max_time=1.0,\n",
    "#                         criterion=MaxUCB(100),\n",
    "#                         estimate_value=value_estimator,\n",
    "#                         enable_action_pw=false,\n",
    "#                         k_observation=2,\n",
    "#                         alpha_observation=0.15,\n",
    "#                         tree_in_info=true)\n",
    "\n",
    "planner = solve(solver, pomdp)\n",
    "b0 = initialstate_distribution(pomdp)\n",
    "@time a, info = action_info(planner, b0)\n",
    "# println(\"number of trials: $(first(info[:record]))\")\n",
    "# println(\"time for building DESPOT: $(last(info[:record]))\")\n",
    "D3Tree(info[:tree], init_expand=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests based on LaserTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_episodes = 100\n",
    "max_steps = 100\n",
    "rng = MersenneTwister(1)\n",
    "\n",
    "dfs = parallel_experiment(pomdp,\n",
    "                          number_of_episodes,\n",
    "                          max_steps,\n",
    "                          solver_list,\n",
    "                          belief_updater=belief_updater,\n",
    "                          initialstate=initialstate(pomdp, rng),\n",
    "                          full_factorial_design=false)\n",
    "\n",
    "# CSV.write(\"LaserTag_LB-DESPOT.csv\", dfs[1])\n",
    "CSV.write(\"LaserTag_UCT-DESPOT.csv\", dfs[1])\n",
    "CSV.write(\"LaserTag_POMCPOW.csv\", dfs[2])\n",
    "CSV.write(\"LaserTag_QMDP.csv\", dfs[3])\n",
    "CSV.write(\"LaserTag_Move_Towards.csv\", dfs[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roomba Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roomba related pkgs\n",
    "# Roomba need ParticleFilters = \"0.2\" for compatibility\n",
    "@everywhere push!(LOAD_PATH, \"../../Roomba\")\n",
    "@everywhere using Roomba # For Roomba Env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bumper Roomba Setting\n",
    "Setting up a Roomba problem with bumper sensor for further using.\\\n",
    "The parameters of Roomba are listed as follows.\n",
    "```\n",
    "maximum velocity of Roomba [m/s]\n",
    "v_max::Float64  = 10.0  # m/s\n",
    "\n",
    "maximum turn-rate of Roombda [rad/s]\n",
    "om_max::Float64 = 1.0   # rad/s\n",
    "\n",
    "simulation time-step [s]\n",
    "dt::Float64     = 0.5   # s\n",
    "\n",
    "penalty for wall-contact\n",
    "contact_pen::Float64 = -1.0 \n",
    "\n",
    "penalty per time-step\n",
    "time_pen::Float64 = -0.1\n",
    "\n",
    "reward for reaching goal\n",
    "goal_reward::Float64 = 10\n",
    "\n",
    "penalty for reaching stairs\n",
    "stairs_penalty::Float64 = -10\n",
    "\n",
    "specifies room configuration (location of stairs/goal) {1,2,3}\n",
    "config::Int = 1\n",
    "\n",
    "environment room struct\n",
    "room::Room  = Room(sspace,configuration=config)\n",
    "\n",
    "environment state-space (ContinuousRoombaStateSpace or DiscreteRoombaStateSpace)\n",
    "sspace::SS = ContinuousRoombaStateSpace()\n",
    "\n",
    "environment action-space struct\n",
    "aspace::AS = RoombaActions()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_speed = 2.0\n",
    "speed_interval = 2.0\n",
    "max_turn_rate = 1.0\n",
    "turn_rate_interval = 1.0\n",
    "\n",
    "sensor = Bumper()\n",
    "num_particles = 5000 # number of particles in belief\n",
    "\n",
    "pos_noise_coeff = 0.3\n",
    "ori_noise_coeff = 0.1\n",
    "\n",
    "# POMDP problem\n",
    "action_space = vec([RoombaAct(v, om) for v in 0:speed_interval:max_speed, om in -max_turn_rate:turn_rate_interval:max_turn_rate])\n",
    "pomdp = RoombaPOMDP(sensor=sensor, mdp=RoombaMDP(aspace=action_space));\n",
    "\n",
    "# Belief updater\n",
    "resampler = BumperResampler(num_particles, pomdp, pos_noise_coeff, ori_noise_coeff)\n",
    "belief_updater = BasicParticleFilter(pomdp, resampler, num_particles)\n",
    "\n",
    "# Rush Policy\n",
    "rush_policy = FunctionPolicy() do b\n",
    "    if !(typeof(b) <: ParticleFilters.ParticleCollection) &&\n",
    "        !(typeof(b) <: Roomba.RoombaInitialDistribution) &&\n",
    "        b !== nothing &&\n",
    "        typeof(b) == Bool ? b : (typeof(currentobs(b)) == Bool ? currentobs(b) : false)\n",
    "\n",
    "        [max_speed, max_turn_rate]\n",
    "    else\n",
    "        [max_speed, 0.0]\n",
    "    end\n",
    "end\n",
    "\n",
    "# For LB-DESPOT\n",
    "bounds = IndependentBounds(DefaultPolicyLB(rush_policy), 10.0, check_terminal=true)\n",
    "random_bounds = IndependentBounds(DefaultPolicyLB(RandomPolicy(pomdp)), 10.0, check_terminal=true)\n",
    "lbdespot_dict = Dict(:default_action=>[rush_policy,], \n",
    "                    :bounds=>[bounds, random_bounds],\n",
    "                    :K=>[100, 300, 500],\n",
    "                    :beta=>[0., 0.1, 1., 10., 100.])\n",
    "\n",
    "# For UCT-DESPOT\n",
    "rollout_policy = rush_policy\n",
    "random_rollout_policy = RandomPolicy(pomdp)\n",
    "uctdespot_dict = Dict(:rollout_policy=>[rollout_policy, random_rollout_policy],\n",
    "                        :K=>[100, 300, 500],\n",
    "                        :m=>[5, 10, 20, 30],\n",
    "                        :c=>[0.1, 1., 10., 100., 1000., 10000.])\n",
    "\n",
    "# For POMCPOW\n",
    "value_estimator = PORollout(rush_policy, PreviousObservationUpdater())\n",
    "random_value_estimator = FORollout(RandomPolicy(pomdp))\n",
    "pomcpow_dict = Dict(:estimate_value=>[value_estimator, random_value_estimator],\n",
    "                    :tree_queries=>[100000,], \n",
    "                    :max_time=>[1.0,], \n",
    "                    :criterion=>[MaxUCB(0.1), MaxUCB(1.0), MaxUCB(10.), MaxUCB(100.), MaxUCB(1000.)])\n",
    "\n",
    "# Solver list\n",
    "solver_list = [LB_DESPOTSolver=>lbdespot_dict, \n",
    "                UCT_DESPOTSolver=>uctdespot_dict, \n",
    "                POMCPOWSolver=>pomcpow_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bumper Roomba Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = LB_DESPOTSolver(bounds=bounds, default_action=rush_policy, tree_in_info=true)\n",
    "solver = UCT_DESPOTSolver(rollout_policy=rollout_policy, tree_in_info=true)\n",
    "# solver = POMCPOWSolver(tree_queries=100000, max_time=1.0, estimate_value=value_estimator, tree_in_info=true)\n",
    "\n",
    "planner = solve(solver, pomdp)\n",
    "makegif(pomdp, planner, belief_updater, filename=\"bumper.gif\", max_steps=100, show_progress=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = LB_DESPOTSolver(bounds=bounds, beta=0.2, T_max=60.0, K=100, default_action=rush_policy, tree_in_info=true)\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=rollout_policy, T_max=60.0, m=10, K=100, c=100, tree_in_info=true)\n",
    "# # solver = POMCPOWSolver(tree_queries=1000000, max_time=20.0, criterion=MaxUCB(1000), estimate_value=value_estimator, tree_in_info=true)\n",
    "\n",
    "# planner = solve(solver, pomdp)\n",
    "# b0 = initialstate_distribution(pomdp)\n",
    "# @time a, info = action_info(planner, b0)\n",
    "# @show info[:record]\n",
    "# D3Tree(info[:tree], init_expand=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests based on Bumper Roomba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_episodes = 1\n",
    "max_steps = 1\n",
    "rng = MersenneTwister(1)\n",
    "\n",
    "dfs = parallel_experiment(pomdp,\n",
    "                          number_of_episodes,\n",
    "                          max_steps,\n",
    "                          solver_list,\n",
    "                          belief_updater=belief_updater,\n",
    "                          initialstate=initialstate(pomdp, rng),\n",
    "                          full_factorial_design=false)\n",
    "\n",
    "for i in 1:length(dfs)\n",
    "    CSV.write(\"BumperRoomba$(i).csv\", dfs[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lidar Roomba Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_speed = 2.0\n",
    "speed_interval = 2.0\n",
    "max_turn_rate = 1.0\n",
    "turn_rate_interval = 1.0\n",
    "\n",
    "sensor = Lidar()\n",
    "num_particles = 5000 # number of particles in belief\n",
    "\n",
    "pos_noise_coeff = 0.3\n",
    "ori_noise_coeff = 0.1\n",
    "\n",
    "# POMDP problem\n",
    "action_space = vec([RoombaAct(v, om) for v in 0:speed_interval:max_speed, om in -max_turn_rate:turn_rate_interval:max_turn_rate])\n",
    "pomdp = RoombaPOMDP(sensor=sensor, mdp=RoombaMDP(config=2, aspace=action_space))\n",
    "\n",
    "# Belief updater\n",
    "resampler = LidarResampler(num_particles, pomdp, pos_noise_coeff, ori_noise_coeff)\n",
    "belief_updater = BasicParticleFilter(pomdp, resampler, num_particles)\n",
    "\n",
    "# Running policy\n",
    "running_policy = FunctionPolicy() do b\n",
    "    # s = typeof(b) == RoombaState ? b : typeof(b) <: AA228FinalProject.RoombaInitialDistribution ? rand(b) : mean(b)\n",
    "    # The statement is computational inefficient.\n",
    "    s = typeof(b) == RoombaState ? b : rand(b)\n",
    "    # compute the difference between our current heading and one that would\n",
    "    # point to the goal\n",
    "    goal_x, goal_y = get_goal_xy(pomdp)\n",
    "    x,y,th = s[1:3]\n",
    "    ang_to_goal = atan(goal_y - y, goal_x - x)\n",
    "    del_angle = wrap_to_pi(ang_to_goal - th)\n",
    "    \n",
    "    # apply proportional control to compute the turn-rate\n",
    "    Kprop = 1.0\n",
    "    om = Kprop * del_angle\n",
    "    # find the closest option in action space\n",
    "    _,ind = findmin(abs.(om .- (-max_turn_rate:turn_rate_interval:max_turn_rate)))\n",
    "    om = (-max_turn_rate:turn_rate_interval:max_turn_rate)[ind]\n",
    "    # always travel at some fixed velocity\n",
    "    v = max_speed\n",
    "    \n",
    "    return RoombaAct(v, om)\n",
    "end\n",
    "\n",
    "# Roomba Upper Bound\n",
    "function shortest_time(pomdp::RoombaPOMDP, b)\n",
    "    s = typeof(b) == RoombaState ? b : rand(b)\n",
    "    x,y,th = s[1:3]\n",
    "    # point to the goal\n",
    "    goal_x, goal_y = get_goal_xy(pomdp)\n",
    "    shortest_dist = sqrt((goal_x - x)^2 + (goal_y - y)^2)\n",
    "    return pomdp.goal_reward + pomdp.time_pen * shortest_dist / max_speed\n",
    "end\n",
    "\n",
    "# Roomba Initializer\n",
    "function n_init(pomdp::RoombaPOMDP, h, a::RoombaAct)\n",
    "    if a.v == 0 && a.omega == 0\n",
    "        return 1\n",
    "    end\n",
    "    return 0\n",
    "end\n",
    "function v_init(pomdp::RoombaPOMDP, h, a::RoombaAct)\n",
    "    if a.v == 0 && a.omega == 0\n",
    "        return -100\n",
    "    end\n",
    "    return 0\n",
    "end\n",
    "\n",
    "function initializer(b, a::RoombaAct)\n",
    "    return (v_init(pomdp, b, a), n_init(pomdp, b, a))\n",
    "end\n",
    "\n",
    "# For LB-DESPOT\n",
    "bounds = IndependentBounds(DefaultPolicyLB(running_policy), 10.0, check_terminal=true)\n",
    "# bounds with heuristic upper bound\n",
    "bounds_hub = IndependentBounds(DefaultPolicyLB(running_policy), shortest_time, check_terminal=true)\n",
    "random_bounds = IndependentBounds(DefaultPolicyLB(RandomPolicy(pomdp)), 10.0, check_terminal=true)\n",
    "lbdespot_dict = Dict(:default_action=>[running_policy,], \n",
    "                    :bounds=>[bounds, random_bounds, bounds_hub],\n",
    "                    :lambda=>[0.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "                    :K=>[100, 300, 500],\n",
    "                    :beta=>[0., 0.1, 1., 10., 100.])\n",
    "\n",
    "# For UCT-DESPOT\n",
    "rollout_policy = running_policy\n",
    "random_rollout_policy = RandomPolicy(pomdp)\n",
    "uctdespot_dict = Dict(:rollout_policy=>[rollout_policy, random_rollout_policy],\n",
    "                        :initializer=>[initializer,],\n",
    "                        :K=>[100, 300, 500],\n",
    "                        :m=>[5, 10, 20, 30],\n",
    "                        :criterion=>[MaxUCB(0.1), MaxUCB(1.0), MaxUCB(10.), MaxUCB(100.), MaxUCB(1000.)])\n",
    "\n",
    "# For POMCPOW\n",
    "value_estimator = FORollout(running_policy)\n",
    "random_value_estimator = FORollout(RandomPolicy(pomdp))\n",
    "pomcpow_dict = Dict(:estimate_value=>[value_estimator, random_value_estimator],\n",
    "                    :init_N=>[n_init,],\n",
    "                    :init_V=>[v_init,],\n",
    "                    :tree_queries=>[100000,], \n",
    "                    :max_time=>[1.0,], \n",
    "                    :c=>[0.1, 1., 10., 100., 1000., 10000.])\n",
    "\n",
    "# Solver list\n",
    "solver_list = [LB_DESPOTSolver=>lbdespot_dict, \n",
    "                UCT_DESPOTSolver=>uctdespot_dict, \n",
    "                POMCPOWSolver=>pomcpow_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lidar Roomba Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver = LB_DESPOTSolver(bounds=bounds, default_action=running_policy)\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=rollout_policy)\n",
    "# solver = POMCPOWSolver(tree_queries=100000, max_time=1.0, estimate_value=value_estimator)\n",
    "\n",
    "# planner = solve(solver, pomdp)\n",
    "# makegif(pomdp, planner, belief_updater, filename=\"lidar.gif\", max_steps=100, show_progress=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # solver = LB_DESPOTSolver(bounds=bounds, default_action=running_policy, tree_in_info=true)\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=rollout_policy, initializer=initializer, tree_in_info=true)\n",
    "# # solver = POMCPOWSolver(tree_queries=100000, max_time=1.0, estimate_value=value_estimator, tree_in_info=true)\n",
    "\n",
    "# planner = solve(solver, pomdp)\n",
    "# b0 = initialstate_distribution(pomdp)\n",
    "# a, info = action_info(planner, b0)\n",
    "# D3Tree(info[:tree], init_expand=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests based on Lidar Roomba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_episodes = 1\n",
    "max_steps = 1\n",
    "rng = MersenneTwister(1)\n",
    "\n",
    "dfs = parallel_experiment(pomdp,\n",
    "                          number_of_episodes,\n",
    "                          max_steps,\n",
    "                          solver_list,\n",
    "                          belief_updater=belief_updater,\n",
    "                          initialstate=initialstate(pomdp, rng),\n",
    "                          full_factorial_design=false)\n",
    "\n",
    "for i in 1:length(dfs)\n",
    "    CSV.write(\"LidarRoomba$(i).csv\", dfs[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Lidar Roomba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_speed = 2.0\n",
    "speed_interval = 2.0\n",
    "max_turn_rate = 1.0\n",
    "turn_rate_interval = 1.0\n",
    "\n",
    "cut_points =  exp10.(range(-.5, stop=1.3, length=10))\n",
    "sensor = DiscreteLidar(cut_points)\n",
    "\n",
    "num_particles = 5000 # number of particles in belief\n",
    "\n",
    "pos_noise_coeff = 0.3\n",
    "ori_noise_coeff = 0.1\n",
    "\n",
    "# POMDP problem\n",
    "action_space = vec([RoombaAct(v, om) for v in 0:speed_interval:max_speed, om in -max_turn_rate:turn_rate_interval:max_turn_rate])\n",
    "pomdp = RoombaPOMDP(sensor=sensor, mdp=RoombaMDP(config=3, aspace=action_space));\n",
    "\n",
    "# Belief updater\n",
    "resampler = LidarResampler(num_particles, pomdp, pos_noise_coeff, ori_noise_coeff)\n",
    "belief_updater = BasicParticleFilter(pomdp, resampler, num_particles)\n",
    "\n",
    "# Running policy\n",
    "running_policy = FunctionPolicy() do b\n",
    "    # s = typeof(b) == RoombaState ? b : typeof(b) <: AA228FinalProject.RoombaInitialDistribution ? rand(b) : mean(b)\n",
    "    # The statement is computational inefficient.\n",
    "    s = typeof(b) == RoombaState ? b : rand(b)\n",
    "    # compute the difference between our current heading and one that would\n",
    "    # point to the goal\n",
    "    goal_x, goal_y = get_goal_xy(pomdp)\n",
    "    x,y,th = s[1:3]\n",
    "    ang_to_goal = atan(goal_y - y, goal_x - x)\n",
    "    del_angle = wrap_to_pi(ang_to_goal - th)\n",
    "    \n",
    "    # apply proportional control to compute the turn-rate\n",
    "    Kprop = 1.0\n",
    "    om = Kprop * del_angle\n",
    "    # find the closest option in action space\n",
    "    _,ind = findmin(abs.(om .- (-max_turn_rate:turn_rate_interval:max_turn_rate)))\n",
    "    om = (-max_turn_rate:turn_rate_interval:max_turn_rate)[ind]\n",
    "    # always travel at some fixed velocity\n",
    "    v = max_speed\n",
    "    \n",
    "    return RoombaAct(v, om)\n",
    "end\n",
    "\n",
    "# Roomba Upper Bound\n",
    "function shortest_time(pomdp::RoombaPOMDP, b)\n",
    "    s = typeof(b) == RoombaState ? b : rand(b)\n",
    "    x,y,th = s[1:3]\n",
    "    # point to the goal\n",
    "    goal_x, goal_y = get_goal_xy(pomdp)\n",
    "    shortest_dist = sqrt((goal_x - x)^2 + (goal_y - y)^2)\n",
    "    return pomdp.mdp.goal_reward + pomdp.mdp.time_pen * shortest_dist / max_speed\n",
    "end\n",
    "\n",
    "# Roomba Initializer\n",
    "function n_init(pomdp::RoombaPOMDP, h, a::RoombaAct)\n",
    "    if a.v == 0 && a.omega == 0\n",
    "        return 1\n",
    "    end\n",
    "    return 0\n",
    "end\n",
    "function v_init(pomdp::RoombaPOMDP, h, a::RoombaAct)\n",
    "    if a.v == 0 && a.omega == 0\n",
    "        return -100.0\n",
    "    end\n",
    "    return 0.0\n",
    "end\n",
    "\n",
    "function initializer(b, a::RoombaAct)\n",
    "    return (v_init(pomdp, b, a), n_init(pomdp, b, a))\n",
    "end\n",
    "\n",
    "# For LB-DESPOT\n",
    "bounds = IndependentBounds(DefaultPolicyLB(running_policy), 10.0, check_terminal=true)\n",
    "# bounds with heuristic upper bound\n",
    "bounds_hub = IndependentBounds(DefaultPolicyLB(running_policy), shortest_time, check_terminal=true)\n",
    "random_bounds = IndependentBounds(DefaultPolicyLB(RandomPolicy(pomdp)), 10.0, check_terminal=true)\n",
    "lbdespot_dict = Dict(:default_action=>[running_policy,], \n",
    "                    :bounds=>[bounds, random_bounds],\n",
    "                    :lambda=>[0.0, 0.01, 0.1, 1.0],\n",
    "                    :T_max=>[30.0],\n",
    "                    :K=>[100, 500],\n",
    "                    :beta=>[0., 0.5, 1., 5.])\n",
    "\n",
    "# For UCT-DESPOT\n",
    "rollout_policy = running_policy\n",
    "random_rollout_policy = RandomPolicy(pomdp)\n",
    "uctdespot_dict = Dict(:rollout_policy=>[rollout_policy, random_rollout_policy],\n",
    "                        :K=>[100, 500],\n",
    "                        :T_max=>[30.0],\n",
    "                        :m=>[10, 50],\n",
    "                        :c=>[1., 10., 100.])\n",
    "\n",
    "# For POMCPOW\n",
    "value_estimator = FORollout(running_policy)\n",
    "random_value_estimator = FORollout(RandomPolicy(pomdp))\n",
    "pomcpow_dict = Dict(:estimate_value=>[value_estimator, random_value_estimator],\n",
    "                    :tree_queries=>[100000,], \n",
    "                    :max_time=>[30.0,], \n",
    "                    :criterion=>[MaxUCB(0.1), MaxUCB(1.0), MaxUCB(10.), MaxUCB(100.), MaxUCB(1000.)])\n",
    "\n",
    "# Solver list\n",
    "solver_list = [#LB_DESPOTSolver=>lbdespot_dict, \n",
    "                UCT_DESPOTSolver=>uctdespot_dict, ]\n",
    "                #POMCPOWSolver=>pomcpow_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Lidar Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = LB_DESPOTSolver(bounds=bounds_hub, beta=0.2, K=500, default_action=running_policy)\n",
    "# solver = UCT_DESPOTSolver(m=10, K=100, c=100, T_max=1, rollout_policy=rollout_policy)\n",
    "# solver = POMCPOWSolver(tree_queries=100000, max_time=1.0, estimate_value=value_estimator)\n",
    "\n",
    "planner = solve(solver, pomdp)\n",
    "makegif(pomdp, planner, belief_updater, filename=\"discrete_lidar.gif\", max_steps=100, show_progress=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = LB_DESPOTSolver(bounds=bounds_hub, T_max=10.0,lambda=1, beta=0.2, K=300, tree_in_info=true)\n",
    "# solver = UCT_DESPOTSolver(rollout_policy=rollout_policy, initializer=initializer, T_max=10.0, m=30, K=1000, c=1, tree_in_info=true)\n",
    "# solver = POMCPOWSolver(tree_queries=100000, max_time=10.0, init_N=n_init, init_V=v_init, criterion=MaxUCB(10), estimate_value=value_estimator, tree_in_info=true)\n",
    "\n",
    "planner = solve(solver, pomdp)\n",
    "b0 = initialstate_distribution(pomdp)\n",
    "a, info = action_info(planner, b0)\n",
    "# println(\"number of trials: $(first(info[:record]))\")\n",
    "# # @show info[:record]\n",
    "# println(\"time for building DESPOT: $(last(info[:record]))\")\n",
    "D3Tree(info[:tree], init_expand=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests based on Discrete Lidar Roomba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_episodes = 1\n",
    "max_steps = 1\n",
    "rng = MersenneTwister(1)\n",
    "\n",
    "dfs = parallel_experiment(pomdp,\n",
    "                          number_of_episodes,\n",
    "                          max_steps,\n",
    "                          solver_list,\n",
    "                          belief_updater=belief_updater,\n",
    "                          initialstate=initialstate(pomdp, rng),\n",
    "                          full_factorial_design=false)\n",
    "\n",
    "CSV.write(\"DiscreteLidarRoomba_LB_DESPOT.csv\", dfs[1])\n",
    "CSV.write(\"DiscreteLidarRoomba_UCT_DESPOT.csv\", dfs[2])\n",
    "CSV.write(\"DiscreteLidarRoomba_POMCPOW.csv\", dfs[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
